{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXC RB simulation\n",
    "\n",
    "Tim Keil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    " # ~~~\n",
    " # This file is part of the paper:\n",
    " #\n",
    " #   \"Model Reduction for Large Scale Systems\"\n",
    " #\n",
    " #   https://github.com/TiKeil/Petrov-Galerkin-TR-RB-for-pde-opt\n",
    " #\n",
    " # Copyright 2019-2021 all developers. All rights reserved.\n",
    " # License: Licensed as BSD 2-Clause License (http://opensource.org/licenses/BSD-2-Clause)\n",
    " # Authors:\n",
    " #   Tim Keil (2019 - 2021)\n",
    " # ~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "path = '../../../EXC_data'\n",
    "sys.path.append(path)\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from pymor.basic import *\n",
    "set_log_levels({'pymor': 'WARN'})\n",
    "set_defaults({'pymor.operators.constructions.induced_norm.raise_negative': False})\n",
    "set_defaults({'pymor.operators.constructions.induced_norm.tol': 1e-20})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymor.core.logger import set_log_levels, getLogger\n",
    "set_log_levels({'pymor': 'ERROR',\n",
    "                'distributed_adaptive_discretizations': 'DEBUG',\n",
    "                'notebook': 'INFO'})\n",
    "logger = getLogger('notebook.notebook')\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = (12.0, 8.0)\n",
    "mpl.rcParams['font.size'] = 12\n",
    "mpl.rcParams['savefig.dpi'] = 300\n",
    "\n",
    "# domain of interest\n",
    "bounding_box = [[0,0],[2,1]]\n",
    "domain_of_interest = ConstantFunction(1,2)     # <-- THIS IS THE DUAL SIMPLIFICATION domain_of_interest = Omega\n",
    "# domain_of_interest = BitmapFunction(f'{path}/Domain_of_interest.png', range=[1,0], bounding_box=bounding_box)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## problem definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am using the NCD corrected functional!!\n",
      "my product is fixed_energy\n",
      "mu_bar is: {doors: [0.1, 0.1], heaters: [10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0], walls: [0.049999999999999996, 0.049999999999999996, 0.049999999999999996]}\n"
     ]
    }
   ],
   "source": [
    "from pdeopt.problems import EXC_problem, set_input_dict\n",
    "from pdeopt.discretizer import discretize_quadratic_pdeopt_stationary_cg\n",
    "\n",
    "parametric_quantities = {'walls': [1,4,9], 'windows': [], 'doors': [6,7], 'heaters': [1,3,5,6,7,8,9]}\n",
    "inactive_quantities = {'removed_walls': [], 'open_windows': [], 'open_doors': [1,2,3,4,5,10], 'active_heaters': []}\n",
    "summed_quantities = {'walls': [[1,2,3,7,8],[4,5,6]], 'windows': [], 'doors': [], 'heaters': [[1,2],[3,4],[9,10,11,12]]}\n",
    "\n",
    "coefficient_expressions = None\n",
    "\n",
    "parameters_in_q = True\n",
    "input_dict = set_input_dict(parametric_quantities, inactive_quantities, coefficient_expressions, summed_quantities, parameters_in_q,\n",
    "                            ac=0.5, owc=[0.025,0.1], iwc= [0.025,0.1], idc=[0.05,0.2], wc=[0.0005], ht=[0,100],\n",
    "                                    owc_c=0.001,  iwc_c= 0.025,     idc_c=0.01,  wc_c=0.05,  ht_c=80)\n",
    "\n",
    "\n",
    "parameter_scaling = False\n",
    "u_out = 5\n",
    "\n",
    "problem, parameter_scales = EXC_problem(input_dict, summed_quantities, outside_temperature=u_out, #, q_inverse=0.0001\n",
    "                                        data_path = path,parameters_in_q=parameters_in_q, \n",
    "                                        parameter_scaling=parameter_scaling,\n",
    "                                        coefficient_expressions=coefficient_expressions)\n",
    "\n",
    "u_d = 18 \n",
    "\n",
    "mu_d = problem.parameter_space.sample_randomly(1, seed=10)[0]\n",
    "mu_d = None\n",
    "\n",
    "sigma_d = 100\n",
    "weights = {'walls': 0.1, 'doors': 1, 'heaters': [0.002,0.002,0.0005,0.0005,0.0005,0.0005,0.004], 'windows': 1, 'state': sigma_d}\n",
    "\n",
    "diameter = np.sqrt(2)/200.\n",
    "opt_fom, data, mu_bar = discretize_quadratic_pdeopt_stationary_cg(problem, diameter, weights, parameter_scales, \n",
    "                                                          domain_of_interest, desired_temperature=u_d, \n",
    "                                                          mu_for_u_d=mu_d, mu_for_tikhonov=mu_d,\n",
    "                                                          parameters_in_q=parameters_in_q, product='fixed_energy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "information on the grid:\n",
      "Rect-Grid on domain [0,2] x [0,1]\n",
      "x0-intervals: 400, x1-intervals: 200\n",
      "faces: 80000, edges: 160600, vertices: 80601\n"
     ]
    }
   ],
   "source": [
    "print('information on the grid:')\n",
    "print(data['grid'])\n",
    "\n",
    "N = [4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60]\n",
    "validation_set_size = 100\n",
    "tau_global_RB_J = 1e-12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classical Model Order Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BFGS-Greedy for non-corrected functional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now construct a simple RB basis for primal, dual and all sensitivities. For this, we start with an empty basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with two bases. Primal and dual have length 0 and 0\n",
      "building simple coercive primal reductor...\n",
      "building simple coercive dual reductor...\n"
     ]
    }
   ],
   "source": [
    "params = []\n",
    "from pdeopt.model import build_initial_basis\n",
    "RBbasis, dual_RBbasis = build_initial_basis(opt_fom, params, build_sensitivities=False)\n",
    "\n",
    "from pdeopt.reductor import QuadraticPdeoptStationaryCoerciveReductor\n",
    "from pdeopt.pg_reductor import QuadraticPdeoptStationaryCoercivePGReductor\n",
    "\n",
    "from pymor.parameters.functionals import MinThetaParameterFunctional\n",
    "\n",
    "ce = MinThetaParameterFunctional(opt_fom.primal_model.operator.coefficients, mu_bar)\n",
    "\n",
    "# opt_fom = opt_fom.with_(use_corrected_functional=False)\n",
    "# opt_fom = opt_fom.with_(adjoint_approach=False)\n",
    "\n",
    "# pdeopt_reductor = QuadraticPdeoptStationaryCoerciveReductor(opt_fom, \n",
    "#                                 RBbasis, dual_RBbasis, opt_product=opt_fom.opt_product,\n",
    "#                                 coercivity_estimator=ce, mu_bar=mu_bar)\n",
    "\n",
    "opt_fom = opt_fom.with_(use_corrected_functional=False)\n",
    "opt_fom = opt_fom.with_(adjoint_approach=False)\n",
    "opt_fom = opt_fom.with_(petrov_galerkin=True) \n",
    "\n",
    "pg_opt_reductor = QuadraticPdeoptStationaryCoercivePGReductor(opt_fom, \n",
    "                        RBbasis, dual_RBbasis, opt_product=opt_fom.opt_product,\n",
    "                        coercivity_estimator=ce, mu_bar=mu_bar, least_squares=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start a greedy for the whole domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Greedy for J target\n",
      "\n",
      "Processing until 4th extension...\n",
      "building simple coercive dual reductor...\n",
      "Enrichment completed... length of Bases are 1 and 1\n",
      "building simple coercive dual reductor...\n",
      "Enrichment completed... length of Bases are 2 and 2\n",
      "building simple coercive dual reductor...\n",
      "Enrichment completed... length of Bases are 3 and 3\n",
      "building simple coercive dual reductor...\n",
      "Enrichment completed... length of Bases are 4 and 4\n",
      "\n",
      "Processing until 8th extension...\n",
      "building simple coercive dual reductor...\n",
      "Enrichment completed... length of Bases are 5 and 5\n",
      "building simple coercive dual reductor...\n",
      "Enrichment completed... length of Bases are 6 and 6\n",
      "building simple coercive dual reductor...\n",
      "Enrichment completed... length of Bases are 7 and 7\n",
      "building simple coercive dual reductor...\n",
      "Enrichment completed... length of Bases are 8 and 8\n",
      "\n",
      "Processing until 12th extension...\n",
      "building simple coercive dual reductor...\n",
      "Enrichment completed... length of Bases are 9 and 9\n",
      "building simple coercive dual reductor...\n",
      "Enrichment completed... length of Bases are 10 and 10\n",
      "building simple coercive dual reductor...\n",
      "Enrichment completed... length of Bases are 11 and 11\n",
      "building simple coercive dual reductor...\n",
      "Enrichment completed... length of Bases are 12 and 12\n",
      "\n",
      "Processing until 16th extension...\n",
      "building simple coercive dual reductor...\n",
      "Enrichment completed... length of Bases are 13 and 13\n",
      "building simple coercive dual reductor...\n",
      "Enrichment completed... length of Bases are 14 and 14\n",
      "building simple coercive dual reductor...\n",
      "Enrichment completed... length of Bases are 15 and 15\n",
      "building simple coercive dual reductor...\n",
      "Enrichment completed... length of Bases are 16 and 16\n",
      "\n",
      "Processing until 20th extension...\n",
      "building simple coercive dual reductor...\n",
      "Enrichment completed... length of Bases are 17 and 17\n",
      "building simple coercive dual reductor...\n",
      "Enrichment completed... length of Bases are 18 and 18\n",
      "building simple coercive dual reductor...\n",
      "Enrichment completed... length of Bases are 19 and 19\n",
      "building simple coercive dual reductor...\n",
      "Enrichment completed... length of Bases are 20 and 20\n",
      "\n",
      "Processing until 24th extension...\n",
      "building simple coercive dual reductor...\n",
      "Enrichment completed... length of Bases are 21 and 21\n",
      "building simple coercive dual reductor...\n",
      "Enrichment completed... length of Bases are 22 and 22\n",
      "building simple coercive dual reductor...\n",
      "Enrichment completed... length of Bases are 23 and 23\n",
      "building simple coercive dual reductor...\n",
      "Enrichment completed... length of Bases are 24 and 24\n",
      "\n",
      "Processing until 28th extension...\n",
      "building simple coercive dual reductor...\n",
      "Enrichment completed... length of Bases are 25 and 25\n",
      "building simple coercive dual reductor...\n",
      "Enrichment completed... length of Bases are 26 and 26\n",
      "building simple coercive dual reductor...\n",
      "Enrichment completed... length of Bases are 27 and 27\n",
      "building simple coercive dual reductor...\n",
      "Enrichment completed... length of Bases are 28 and 28\n",
      "\n",
      "Processing until 32th extension...\n",
      "building simple coercive dual reductor...\n",
      "Enrichment completed... length of Bases are 29 and 29\n",
      "building simple coercive dual reductor...\n",
      "Enrichment completed... length of Bases are 30 and 30\n",
      "building simple coercive dual reductor...\n",
      "Enrichment completed... length of Bases are 31 and 31\n",
      "building simple coercive dual reductor...\n",
      "Enrichment completed... length of Bases are 32 and 32\n",
      "\n",
      "Processing until 36th extension...\n",
      "building simple coercive dual reductor...\n",
      "Enrichment completed... length of Bases are 33 and 33\n",
      "building simple coercive dual reductor...\n",
      "Enrichment completed... length of Bases are 34 and 34\n",
      "building simple coercive dual reductor...\n",
      "Enrichment completed... length of Bases are 35 and 35\n",
      "building simple coercive dual reductor...\n",
      "Enrichment completed... length of Bases are 36 and 36\n",
      "\n",
      "Processing until 40th extension...\n",
      "building simple coercive dual reductor...\n",
      "Enrichment completed... length of Bases are 37 and 37\n",
      "building simple coercive dual reductor...\n",
      "Enrichment completed... length of Bases are 38 and 38\n",
      "building simple coercive dual reductor...\n",
      "Enrichment completed... length of Bases are 39 and 39\n",
      "building simple coercive dual reductor...\n",
      "Enrichment completed... length of Bases are 40 and 40\n",
      "\n",
      "Processing until 44th extension...\n",
      "building simple coercive dual reductor...\n",
      "Enrichment completed... length of Bases are 41 and 41\n",
      "building simple coercive dual reductor...\n",
      "Enrichment completed... length of Bases are 42 and 42\n",
      "building simple coercive dual reductor...\n",
      "Enrichment completed... length of Bases are 43 and 43\n",
      "building simple coercive dual reductor...\n",
      "Enrichment completed... length of Bases are 44 and 44\n",
      "\n",
      "Processing until 48th extension...\n",
      "building simple coercive dual reductor...\n",
      "Enrichment completed... length of Bases are 45 and 45\n",
      "building simple coercive dual reductor...\n",
      "Enrichment completed... length of Bases are 46 and 46\n",
      "building simple coercive dual reductor...\n",
      "Enrichment completed... length of Bases are 47 and 47\n",
      "building simple coercive dual reductor...\n",
      "Enrichment completed... length of Bases are 48 and 48\n",
      "\n",
      "Processing until 52th extension...\n",
      "building simple coercive dual reductor...\n",
      "Enrichment completed... length of Bases are 49 and 49\n",
      "building simple coercive dual reductor...\n",
      "Enrichment completed... length of Bases are 50 and 50\n",
      "building simple coercive dual reductor...\n",
      "Enrichment completed... length of Bases are 51 and 51\n",
      "building simple coercive dual reductor...\n",
      "Enrichment completed... length of Bases are 52 and 52\n",
      "\n",
      "Processing until 56th extension...\n",
      "building simple coercive dual reductor...\n",
      "Enrichment completed... length of Bases are 53 and 53\n",
      "building simple coercive dual reductor...\n",
      "Enrichment completed... length of Bases are 54 and 54\n",
      "building simple coercive dual reductor...\n",
      "Enrichment completed... length of Bases are 55 and 55\n",
      "building simple coercive dual reductor...\n",
      "Enrichment completed... length of Bases are 56 and 56\n",
      "\n",
      "Processing until 60th extension...\n",
      "building simple coercive dual reductor...\n",
      "Enrichment completed... length of Bases are 57 and 57\n",
      "building simple coercive dual reductor...\n",
      "Enrichment completed... length of Bases are 58 and 58\n",
      "building simple coercive dual reductor...\n",
      "Enrichment completed... length of Bases are 59 and 59\n",
      "building simple coercive dual reductor...\n",
      "Enrichment completed... length of Bases are 60 and 60\n",
      " ... finished after 60 extensions\n",
      "Greedy took 12179.115653514862\n"
     ]
    }
   ],
   "source": [
    "set_log_levels({'pymor': 'WARN'})  # <-- set this to 'INFO' if you want to have further details \n",
    "from pdeopt.greedy import pdeopt_adaptive_greedy_for_N_list\n",
    "training_set = problem.parameter_space.sample_randomly(10000)\n",
    "\n",
    "opt_roms_3, result_J = pdeopt_adaptive_greedy_for_N_list(\n",
    "    opt_fom, pg_opt_reductor, problem.parameter_space, Nlist=N, validation_mus=training_set, \n",
    "    J_atol=tau_global_RB_J)\n",
    "tictoc = result_J['time']\n",
    "print('Greedy took {}'.format(tictoc))\n",
    "picked_mus = result_J['max_err_mus']\n",
    "assert len(picked_mus) == N[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The max error was:  0.0027352573585843016\n"
     ]
    }
   ],
   "source": [
    "print(f'The max error was: ', result_J['max_errs'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = picked_mus\n",
    "RBbasis, dual_RBbasis = build_initial_basis(opt_fom, params, build_sensitivities=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uncorrected Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with two bases. Primal and dual have length 60 and 60\n",
      "building simple coercive primal reductor...\n",
      "building simple coercive dual reductor...\n",
      "Starting with two bases. Primal and dual have length 4 and 4\n",
      "building simple coercive primal reductor...\n",
      "building simple coercive dual reductor...\n",
      "Starting with two bases. Primal and dual have length 8 and 8\n",
      "building simple coercive primal reductor...\n",
      "building simple coercive dual reductor...\n",
      "Starting with two bases. Primal and dual have length 12 and 12\n",
      "building simple coercive primal reductor...\n",
      "building simple coercive dual reductor...\n",
      "Starting with two bases. Primal and dual have length 16 and 16\n",
      "building simple coercive primal reductor...\n",
      "building simple coercive dual reductor...\n",
      "Starting with two bases. Primal and dual have length 20 and 20\n",
      "building simple coercive primal reductor...\n",
      "building simple coercive dual reductor...\n",
      "Starting with two bases. Primal and dual have length 24 and 24\n",
      "building simple coercive primal reductor...\n",
      "building simple coercive dual reductor...\n",
      "Starting with two bases. Primal and dual have length 28 and 28\n",
      "building simple coercive primal reductor...\n",
      "building simple coercive dual reductor...\n",
      "Starting with two bases. Primal and dual have length 32 and 32\n",
      "building simple coercive primal reductor...\n",
      "building simple coercive dual reductor...\n",
      "Starting with two bases. Primal and dual have length 36 and 36\n",
      "building simple coercive primal reductor...\n",
      "building simple coercive dual reductor...\n",
      "Starting with two bases. Primal and dual have length 40 and 40\n",
      "building simple coercive primal reductor...\n",
      "building simple coercive dual reductor...\n",
      "Starting with two bases. Primal and dual have length 44 and 44\n",
      "building simple coercive primal reductor...\n",
      "building simple coercive dual reductor...\n",
      "Starting with two bases. Primal and dual have length 48 and 48\n",
      "building simple coercive primal reductor...\n",
      "building simple coercive dual reductor...\n",
      "Starting with two bases. Primal and dual have length 52 and 52\n",
      "building simple coercive primal reductor...\n",
      "building simple coercive dual reductor...\n",
      "Starting with two bases. Primal and dual have length 56 and 56\n",
      "building simple coercive primal reductor...\n",
      "building simple coercive dual reductor...\n"
     ]
    }
   ],
   "source": [
    "opt_fom = opt_fom.with_(use_corrected_functional=False)\n",
    "opt_fom = opt_fom.with_(adjoint_approach=False)\n",
    "opt_fom = opt_fom.with_(petrov_galerkin=False) \n",
    "\n",
    "pdeopt_reductor = QuadraticPdeoptStationaryCoerciveReductor(opt_fom, \n",
    "                                RBbasis, dual_RBbasis, opt_product=opt_fom.opt_product,\n",
    "                                coercivity_estimator=ce, mu_bar=mu_bar)\n",
    "\n",
    "opt_roms_1 = []\n",
    "for N_ in N:\n",
    "    opt_roms_1.append(pdeopt_reductor.reduce_to_subbasis(N_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NCD-corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with two bases. Primal and dual have length 60 and 60\n",
      "building simple coercive primal reductor...\n",
      "building simple coercive dual reductor...\n",
      "Starting with two bases. Primal and dual have length 4 and 4\n",
      "building simple coercive primal reductor...\n",
      "building simple coercive dual reductor...\n",
      "Starting with two bases. Primal and dual have length 8 and 8\n",
      "building simple coercive primal reductor...\n",
      "building simple coercive dual reductor...\n",
      "Starting with two bases. Primal and dual have length 12 and 12\n",
      "building simple coercive primal reductor...\n",
      "building simple coercive dual reductor...\n",
      "Starting with two bases. Primal and dual have length 16 and 16\n",
      "building simple coercive primal reductor...\n",
      "building simple coercive dual reductor...\n",
      "Starting with two bases. Primal and dual have length 20 and 20\n",
      "building simple coercive primal reductor...\n",
      "building simple coercive dual reductor...\n",
      "Starting with two bases. Primal and dual have length 24 and 24\n",
      "building simple coercive primal reductor...\n",
      "building simple coercive dual reductor...\n",
      "Starting with two bases. Primal and dual have length 28 and 28\n",
      "building simple coercive primal reductor...\n",
      "building simple coercive dual reductor...\n",
      "Starting with two bases. Primal and dual have length 32 and 32\n",
      "building simple coercive primal reductor...\n",
      "building simple coercive dual reductor...\n",
      "Starting with two bases. Primal and dual have length 36 and 36\n",
      "building simple coercive primal reductor...\n",
      "building simple coercive dual reductor...\n",
      "Starting with two bases. Primal and dual have length 40 and 40\n",
      "building simple coercive primal reductor...\n",
      "building simple coercive dual reductor...\n",
      "Starting with two bases. Primal and dual have length 44 and 44\n",
      "building simple coercive primal reductor...\n",
      "building simple coercive dual reductor...\n",
      "Starting with two bases. Primal and dual have length 48 and 48\n",
      "building simple coercive primal reductor...\n",
      "building simple coercive dual reductor...\n",
      "Starting with two bases. Primal and dual have length 52 and 52\n",
      "building simple coercive primal reductor...\n",
      "building simple coercive dual reductor...\n",
      "Starting with two bases. Primal and dual have length 56 and 56\n",
      "building simple coercive primal reductor...\n",
      "building simple coercive dual reductor...\n"
     ]
    }
   ],
   "source": [
    "from pymor.parameters.functionals import MinThetaParameterFunctional\n",
    "\n",
    "ce = MinThetaParameterFunctional(opt_fom.primal_model.operator.coefficients, mu_bar)\n",
    "\n",
    "opt_fom = opt_fom.with_(use_corrected_functional=True)\n",
    "opt_fom = opt_fom.with_(adjoint_approach=True)\n",
    "\n",
    "ncd_opt_reductor = QuadraticPdeoptStationaryCoerciveReductor(opt_fom, \n",
    "                            RBbasis, dual_RBbasis, opt_product=opt_fom.opt_product,\n",
    "                            coercivity_estimator=ce, mu_bar=mu_bar)\n",
    "\n",
    "\n",
    "opt_roms_2 = []\n",
    "for N_ in N:\n",
    "    opt_roms_2.append(ncd_opt_reductor.reduce_to_subbasis(N_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model LSQ PG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with two bases. Primal and dual have length 60 and 60\n",
      "building simple coercive primal reductor...\n",
      "building simple coercive dual reductor...\n",
      "Starting with two bases. Primal and dual have length 4 and 4\n",
      "building simple coercive primal reductor...\n",
      "building simple coercive dual reductor...\n",
      "Starting with two bases. Primal and dual have length 8 and 8\n",
      "building simple coercive primal reductor...\n",
      "building simple coercive dual reductor...\n",
      "Starting with two bases. Primal and dual have length 12 and 12\n",
      "building simple coercive primal reductor...\n",
      "building simple coercive dual reductor...\n",
      "Starting with two bases. Primal and dual have length 16 and 16\n",
      "building simple coercive primal reductor...\n",
      "building simple coercive dual reductor...\n",
      "Starting with two bases. Primal and dual have length 20 and 20\n",
      "building simple coercive primal reductor...\n",
      "building simple coercive dual reductor...\n",
      "Starting with two bases. Primal and dual have length 24 and 24\n",
      "building simple coercive primal reductor...\n",
      "building simple coercive dual reductor...\n",
      "Starting with two bases. Primal and dual have length 28 and 28\n",
      "building simple coercive primal reductor...\n",
      "building simple coercive dual reductor...\n",
      "Starting with two bases. Primal and dual have length 32 and 32\n",
      "building simple coercive primal reductor...\n",
      "building simple coercive dual reductor...\n",
      "Starting with two bases. Primal and dual have length 36 and 36\n",
      "building simple coercive primal reductor...\n",
      "building simple coercive dual reductor...\n",
      "Starting with two bases. Primal and dual have length 40 and 40\n",
      "building simple coercive primal reductor...\n",
      "building simple coercive dual reductor...\n",
      "Starting with two bases. Primal and dual have length 44 and 44\n",
      "building simple coercive primal reductor...\n",
      "building simple coercive dual reductor...\n",
      "Starting with two bases. Primal and dual have length 48 and 48\n",
      "building simple coercive primal reductor...\n",
      "building simple coercive dual reductor...\n",
      "Starting with two bases. Primal and dual have length 52 and 52\n",
      "building simple coercive primal reductor...\n",
      "building simple coercive dual reductor...\n",
      "Starting with two bases. Primal and dual have length 56 and 56\n",
      "building simple coercive primal reductor...\n",
      "building simple coercive dual reductor...\n"
     ]
    }
   ],
   "source": [
    "opt_fom = opt_fom.with_(use_corrected_functional=False)\n",
    "opt_fom = opt_fom.with_(adjoint_approach=False)\n",
    "opt_fom = opt_fom.with_(petrov_galerkin=True) \n",
    "\n",
    "lsq_opt_reductor = QuadraticPdeoptStationaryCoercivePGReductor(opt_fom, \n",
    "                        RBbasis, dual_RBbasis, opt_product=opt_fom.opt_product,\n",
    "                        coercivity_estimator=ce, mu_bar=mu_bar, least_squares=True)\n",
    "\n",
    "opt_roms_4 = []\n",
    "for N_ in N:\n",
    "    opt_roms_4.append(lsq_opt_reductor.reduce_to_subbasis(N_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compute true errors and estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_set = problem.parameter_space.sample_randomly(validation_set_size, seed=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing expensive FOM parts\n",
      "....................................................................................................\n",
      "computing the rest\n",
      ".."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/t_keil02/lrb-for-pde-opt-code/pymor/src/pymor/operators/numpy.py:322: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  R, _, _, _ = np.linalg.lstsq(self.matrix, V.to_numpy().T)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................."
     ]
    }
   ],
   "source": [
    "from pdeopt.tools import compute_all_errors_and_estimators_for_all_ROMS\n",
    "\n",
    "J_errors_1s, rel_J_errors_1s, J_estimators_1s, effectivities_J_1s, \\\n",
    "J_errors_2s, rel_J_errors_2s, J_estimators_2s, effectivities_J_2s, \\\n",
    "J_errors_3s, rel_J_errors_3s, J_estimators_3s, effectivities_J_3s, \\\n",
    "J_errors_4s, rel_J_errors_4s, J_estimators_4s, effectivities_J_4s, \\\n",
    "DJ_errors_1s, rel_DJ_errors_1s, \\\n",
    "DJ_errors_2s, rel_DJ_errors_2s, \\\n",
    "DJ_errors_3s, rel_DJ_errors_3s, \\\n",
    "DJ_errors_4s, rel_DJ_errors_4s, \\\n",
    "Js, \\\n",
    "u_errors_4s, rel_u_errors_4s, u_estimators_4s, effectivities_u_4s, \\\n",
    "u_errors_2s, rel_u_errors_2s, u_estimators_2s, effectivities_u_2s, \\\n",
    "p_errors_4s, rel_p_errors_4s, p_estimators_4s, effectivities_p_4s, \\\n",
    "p_errors_2s, rel_p_errors_2s, p_estimators_2s, effectivities_p_2s \\\n",
    "        = compute_all_errors_and_estimators_for_all_ROMS(\n",
    "    validation_set, opt_fom, opt_roms_1, opt_roms_2, opt_roms_3, opt_roms_4,\n",
    "    pg_opt_reductor, ncd_opt_reductor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "J_data_for_N = []\n",
    "DJ_data_for_N = []\n",
    "u_data_for_N = []\n",
    "p_data_for_N = []\n",
    "\n",
    "for (\n",
    "J_errors_1, rel_J_errors_1, J_estimators_1, effectivities_J_1,\n",
    "J_errors_2, rel_J_errors_2, J_estimators_2, effectivities_J_2,\n",
    "J_errors_3, rel_J_errors_3, J_estimators_3, effectivities_J_3,\n",
    "J_errors_4, rel_J_errors_4, J_estimators_4, effectivities_J_4,\n",
    "DJ_errors_1, rel_DJ_errors_1, \\\n",
    "DJ_errors_2, rel_DJ_errors_2, \\\n",
    "DJ_errors_3, rel_DJ_errors_3, \\\n",
    "DJ_errors_4, rel_DJ_errors_4, \\\n",
    "J,\n",
    "u_errors_4, rel_u_errors_4, u_estimators_4, effectivities_u_4,\n",
    "u_errors_2, rel_u_errors_2, u_estimators_2, effectivities_u_2,\n",
    "p_errors_4, rel_p_errors_4, p_estimators_4, effectivities_p_4,\n",
    "p_errors_2, rel_p_errors_2, p_estimators_2, effectivities_p_2 \n",
    ") in zip(\n",
    "J_errors_1s, rel_J_errors_1s, J_estimators_1s, effectivities_J_1s,\n",
    "J_errors_2s, rel_J_errors_2s, J_estimators_2s, effectivities_J_2s,\n",
    "J_errors_3s, rel_J_errors_3s, J_estimators_3s, effectivities_J_3s,\n",
    "J_errors_4s, rel_J_errors_4s, J_estimators_4s, effectivities_J_4s,\n",
    "DJ_errors_1s, rel_DJ_errors_1s, \\\n",
    "DJ_errors_2s, rel_DJ_errors_2s, \\\n",
    "DJ_errors_3s, rel_DJ_errors_3s, \\\n",
    "DJ_errors_4s, rel_DJ_errors_4s, \\\n",
    "Js, \n",
    "u_errors_4s, rel_u_errors_4s, u_estimators_4s, effectivities_u_4s,\n",
    "u_errors_2s, rel_u_errors_2s, u_estimators_2s, effectivities_u_2s,\n",
    "p_errors_4s, rel_p_errors_4s, p_estimators_4s, effectivities_p_4s,\n",
    "p_errors_2s, rel_p_errors_2s, p_estimators_2s, effectivities_p_2s \n",
    "):\n",
    "    #J\n",
    "    max_J_err_1 = max(J_errors_1)\n",
    "    min_J_err_1 = min(J_errors_1)\n",
    "\n",
    "    max_J_err_2 = max(J_errors_2)\n",
    "    min_J_err_2 = min(J_errors_2)\n",
    "\n",
    "    max_J_err_3 = max(J_errors_3)\n",
    "    min_J_err_3 = min(J_errors_3)\n",
    "\n",
    "    max_J_err_4 = max(J_errors_4)\n",
    "    min_J_err_4 = min(J_errors_4)\n",
    "        \n",
    "    #J estimator\n",
    "    max_J_est_1 = max(J_estimators_1)\n",
    "    min_J_est_1 = min(J_estimators_1)\n",
    "\n",
    "    max_J_est_2 = max(J_estimators_2)\n",
    "    min_J_est_2 = min(J_estimators_2)\n",
    "\n",
    "    max_J_est_3 = max(J_estimators_3)\n",
    "    min_J_est_3 = min(J_estimators_3)\n",
    "\n",
    "    max_J_est_4 = max(J_estimators_4)\n",
    "    min_J_est_4 = min(J_estimators_4)\n",
    "    \n",
    "    max_eff_J_1 = max(effectivities_J_1)\n",
    "    max_eff_J_2 = max(effectivities_J_2)\n",
    "    max_eff_J_3 = max(effectivities_J_3)\n",
    "    max_eff_J_4 = max(effectivities_J_4)\n",
    "\n",
    "    J_data_for_N.append([\n",
    "        [max_J_err_1, max_J_est_1, min_J_est_1, min_J_err_1, max_eff_J_1],\n",
    "        [max_J_err_2, max_J_est_2, min_J_est_2, min_J_err_2, max_eff_J_2],\n",
    "        [max_J_err_3, max_J_est_3, min_J_est_3, min_J_err_3, max_eff_J_3],\n",
    "        [max_J_err_4, max_J_est_4, min_J_est_4, min_J_err_4, max_eff_J_4]])\n",
    "    \n",
    "    #DJ\n",
    "    max_DJ_err_1 = max(DJ_errors_1)\n",
    "    min_DJ_err_1 = min(DJ_errors_1)\n",
    "\n",
    "    max_DJ_err_2 = max(DJ_errors_2)\n",
    "    min_DJ_err_2 = min(DJ_errors_2)\n",
    "\n",
    "    max_DJ_err_3 = max(DJ_errors_3)\n",
    "    min_DJ_err_3 = min(DJ_errors_3)\n",
    "\n",
    "    max_DJ_err_4 = max(DJ_errors_4)\n",
    "    min_DJ_err_4 = min(DJ_errors_4)\n",
    "    \n",
    "    DJ_data_for_N.append([\n",
    "        [max_DJ_err_1, min_DJ_err_1],\n",
    "        [max_DJ_err_2, min_DJ_err_2],\n",
    "        [max_DJ_err_3, min_DJ_err_3],\n",
    "        [max_DJ_err_4, min_DJ_err_4]])\n",
    "    \n",
    "    # primal\n",
    "    max_u_err_4 = max(u_errors_4)\n",
    "    min_u_err_4 = min(u_errors_4)\n",
    "\n",
    "    max_u_err_2 = max(u_errors_2)\n",
    "    min_u_err_2 = min(u_errors_2)\n",
    "\n",
    "    max_u_est_4 = max(u_estimators_4)\n",
    "    min_u_est_4 = min(u_estimators_4)\n",
    "\n",
    "    max_u_est_2 = max(u_estimators_2)\n",
    "    min_u_est_2 = min(u_estimators_2)\n",
    "    \n",
    "    max_eff_u_4 = max(effectivities_u_4)\n",
    "    max_eff_u_2 = max(effectivities_u_2)\n",
    "\n",
    "    u_data_for_N.append([\n",
    "        [max_u_err_2, max_u_est_2, min_u_est_2, min_u_err_2, max_eff_u_2],\n",
    "        [max_u_err_4, max_u_est_4, min_u_est_4, min_u_err_4, max_eff_u_4]])\n",
    "    \n",
    "    # dual\n",
    "    max_p_err_4 = max(p_errors_4)\n",
    "    min_p_err_4 = min(p_errors_4)\n",
    "\n",
    "    max_p_err_2 = max(p_errors_2)\n",
    "    min_p_err_2 = min(p_errors_2)\n",
    "\n",
    "    max_p_est_4 = max(p_estimators_4)\n",
    "    min_p_est_4 = min(p_estimators_4)\n",
    "\n",
    "    max_p_est_2 = max(p_estimators_2)\n",
    "    min_p_est_2 = min(p_estimators_2)\n",
    "\n",
    "    max_eff_p_4 = max(effectivities_p_4)\n",
    "    max_eff_p_2 = max(effectivities_p_2)\n",
    "    \n",
    "    p_data_for_N.append([\n",
    "        [max_p_err_2, max_p_est_2, min_p_est_2, min_p_err_2, max_eff_p_2],\n",
    "        [max_p_err_4, max_p_est_4, min_p_est_4, min_p_err_4, max_eff_p_4]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## J functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max J error comparison\n",
      "\n",
      "|   basis size |   1 non corr |   2 ncd corr |      3 pg |   4 pg lsq |\n",
      "|--------------|--------------|--------------|-----------|------------|\n",
      "|            4 |   43.0423546 |    4.3567802 | 3.9085827 |  3.9085827 |\n",
      "|            8 |    4.7622899 |    0.9740319 | 1.2450593 |  1.2450593 |\n",
      "|           12 |    3.8108226 |    0.7101863 | 0.7329396 |  0.7329396 |\n",
      "|           16 |    2.3004248 |    0.2501180 | 0.3251995 |  0.3251995 |\n",
      "|           20 |    0.9208100 |    0.0288619 | 0.0247842 |  0.0247842 |\n",
      "|           24 |    0.1874082 |    0.0110932 | 0.0110414 |  0.0110414 |\n",
      "|           28 |    0.1138518 |    0.0053377 | 0.0072402 |  0.0072402 |\n",
      "|           32 |    0.0583603 |    0.0025348 | 0.0094383 |  0.0094383 |\n",
      "|           36 |    0.0300142 |    0.0010780 | 0.0029239 |  0.0029239 |\n",
      "|           40 |    0.0269577 |    0.0002019 | 0.0019345 |  0.0019344 |\n",
      "|           44 |    0.0338155 |    0.0001357 | 0.0011918 |  0.0011918 |\n",
      "|           48 |    0.0187490 |    0.0000615 | 0.0000691 |  0.0000691 |\n",
      "|           52 |    0.0172461 |    0.0000577 | 0.0000789 |  0.0000788 |\n",
      "|           56 |    0.0165199 |    0.0000448 | 0.0000418 |  0.0000418 |\n",
      "|           60 |    0.0077635 |    0.0000329 | 0.0000387 |  0.0000387 |\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "# tabulate for the output functional\n",
    "print('max J error comparison')\n",
    "print()\n",
    "headers = ['basis size', '1 non corr', '2 ncd corr', '3 pg', '4 pg lsq']\n",
    "table = []\n",
    "for i, N_ in enumerate(N):\n",
    "    data = J_data_for_N[i]\n",
    "    table.append([N_, data[0][0], data[1][0], data[2][0], data[3][0]])\n",
    "\n",
    "print(tabulate(table, headers=headers, tablefmt='github', floatfmt='.7f')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max J estimator comparison\n",
      "\n",
      "|   basis size |   1 non corr |   2 ncd corr |         3 pg |     4 pg lsq |\n",
      "|--------------|--------------|--------------|--------------|--------------|\n",
      "|            4 | 3165.1702510 | 3141.2143878 | 3277.0454946 | 3277.0454946 |\n",
      "|            8 |  264.4047738 |  264.2879019 |  545.0150992 |  545.0150992 |\n",
      "|           12 |   37.3756536 |   37.0016027 |   64.5876599 |   64.5876599 |\n",
      "|           16 |   24.7483852 |   24.6490924 |  246.4429782 |  246.4429783 |\n",
      "|           20 |    8.5186668 |    8.1608033 |  151.7949229 |  151.7949229 |\n",
      "|           24 |    0.5755556 |    0.4040536 |   17.5848934 |   17.5848934 |\n",
      "|           28 |    0.2129657 |    0.1497437 |    0.4789816 |    0.4789816 |\n",
      "|           32 |    0.1523195 |    0.1107386 |    0.8466747 |    0.8466747 |\n",
      "|           36 |    0.0635487 |    0.0419511 |    0.2404652 |    0.2404652 |\n",
      "|           40 |    0.0420447 |    0.0155598 |    0.6808230 |    0.6808230 |\n",
      "|           44 |    0.0363611 |    0.0058217 |    0.9137093 |    0.9137093 |\n",
      "|           48 |    0.0200289 |    0.0024353 |    0.0306121 |    0.0306121 |\n",
      "|           52 |    0.0174715 |    0.0019146 |    0.0157254 |    0.0157254 |\n",
      "|           56 |    0.0181853 |    0.0016206 |    0.0053689 |    0.0053689 |\n",
      "|           60 |    0.0086251 |    0.0008287 |    0.0060100 |    0.0060100 |\n"
     ]
    }
   ],
   "source": [
    "# tabulate for the output functional\n",
    "print('max J estimator comparison')\n",
    "print()\n",
    "headers = ['basis size', '1 non corr', '2 ncd corr', '3 pg', '4 pg lsq']\n",
    "table = []\n",
    "for i, N_ in enumerate(N):\n",
    "    data = J_data_for_N[i]\n",
    "    table.append([N_, data[0][1], data[1][1], data[2][1], data[3][1]])\n",
    "\n",
    "print(tabulate(table, headers=headers, tablefmt='github', floatfmt='.7f')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J eff comparison\n",
      "\n",
      "|   basis size |   2 ncd corr |          3 pg |\n",
      "|--------------|--------------|---------------|\n",
      "|            4 | 2780.5649445 | 28347.7240646 |\n",
      "|            8 | 3304.8898695 |  6833.3901719 |\n",
      "|           12 | 6663.4911970 |  3913.9630331 |\n",
      "|           16 | 5379.7668375 |  5732.3049660 |\n",
      "|           20 |  681.5003855 |  9557.1913710 |\n",
      "|           24 |  206.2444367 | 35940.4294551 |\n",
      "|           28 |  162.8181683 |  8328.2859095 |\n",
      "|           32 |  369.2394059 | 11471.2290458 |\n",
      "|           36 |   56.2191137 |  5801.3743077 |\n",
      "|           40 |  515.9271523 | 14414.6747569 |\n",
      "|           44 |   13.6578515 | 15038.8735065 |\n",
      "|           48 |  182.0675118 |  1753.0961699 |\n",
      "|           52 |   11.6191282 |  3150.0345512 |\n",
      "|           56 |   14.7804744 |  2664.8572529 |\n",
      "|           60 |    4.8136181 | 11375.3152282 |\n"
     ]
    }
   ],
   "source": [
    "# tabulate for the output functional\n",
    "print('J eff comparison')\n",
    "print()\n",
    "headers = ['basis size', '2 ncd corr', '3 pg']\n",
    "table = []\n",
    "for i, N_ in enumerate(N):\n",
    "    data = J_data_for_N[i]\n",
    "    table.append([N_, data[0][4], data[1][4]])\n",
    "\n",
    "print(tabulate(table, headers=headers, tablefmt='github', floatfmt='.7f'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DJ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max J error comparison\n",
      "\n",
      "|   basis size |   1 non corr |   2 ncd corr |        3 pg |    4 pg lsq |\n",
      "|--------------|--------------|--------------|-------------|-------------|\n",
      "|            4 |  113.8903117 |  116.8902273 | 116.9413910 | 116.9413910 |\n",
      "|            8 |   78.8674009 |   71.2875380 |  81.3719586 |  81.3719586 |\n",
      "|           12 |   66.5765970 |   53.3466076 |  43.7234391 |  43.7234391 |\n",
      "|           16 |   41.4825594 |   21.9862603 |  37.3951660 |  37.3951660 |\n",
      "|           20 |    3.3217361 |    1.4742002 |   1.3646116 |   1.3646116 |\n",
      "|           24 |    0.9909078 |    0.4527781 |   0.6264351 |   0.6264351 |\n",
      "|           28 |    0.6019228 |    0.2880695 |   0.3770512 |   0.3770512 |\n",
      "|           32 |    0.5208526 |    0.1328267 |   0.4323930 |   0.4323930 |\n",
      "|           36 |    0.3999896 |    0.0677626 |   0.1604367 |   0.1604367 |\n",
      "|           40 |    0.0916279 |    0.0183905 |   0.0830978 |   0.0830978 |\n",
      "|           44 |    0.0960969 |    0.0082919 |   0.1297149 |   0.1297149 |\n",
      "|           48 |    0.0418367 |    0.0036965 |   0.0083390 |   0.0083390 |\n",
      "|           52 |    0.0430256 |    0.0053584 |   0.0044400 |   0.0044400 |\n",
      "|           56 |    0.0365259 |    0.0018361 |   0.0021994 |   0.0021994 |\n",
      "|           60 |    0.0224140 |    0.0018599 |   0.0033864 |   0.0033864 |\n"
     ]
    }
   ],
   "source": [
    "print('max J error comparison')\n",
    "print()\n",
    "headers = ['basis size', '1 non corr', '2 ncd corr', '3 pg', '4 pg lsq']\n",
    "table = []\n",
    "for i, N_ in enumerate(N):\n",
    "    data = DJ_data_for_N[i]\n",
    "    table.append([N_, data[0][0], data[1][0], data[2][0], data[3][0]])\n",
    "\n",
    "print(tabulate(table, headers=headers, tablefmt='github', floatfmt='.7f')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## primal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u error comparison\n",
      "\n",
      "|   basis size |   2 ncd corr |      3 pg |\n",
      "|--------------|--------------|-----------|\n",
      "|            4 |    0.6979035 | 0.7062068 |\n",
      "|            8 |    0.1683773 | 0.3404906 |\n",
      "|           12 |    0.0880920 | 0.1114368 |\n",
      "|           16 |    0.0661280 | 0.1809833 |\n",
      "|           20 |    0.0349068 | 0.1392032 |\n",
      "|           24 |    0.0068316 | 0.0474685 |\n",
      "|           28 |    0.0045575 | 0.0073499 |\n",
      "|           32 |    0.0036580 | 0.0077065 |\n",
      "|           36 |    0.0026852 | 0.0051511 |\n",
      "|           40 |    0.0012673 | 0.0101835 |\n",
      "|           44 |    0.0009064 | 0.0090959 |\n",
      "|           48 |    0.0005655 | 0.0016053 |\n",
      "|           52 |    0.0003778 | 0.0006615 |\n",
      "|           56 |    0.0003298 | 0.0005745 |\n",
      "|           60 |    0.0002402 | 0.0006952 |\n"
     ]
    }
   ],
   "source": [
    "# tabulate for the output functional\n",
    "print('u error comparison')\n",
    "print()\n",
    "headers = ['basis size', '2 ncd corr', '3 pg']\n",
    "table = []\n",
    "for i, N_ in enumerate(N):\n",
    "    data = u_data_for_N[i]\n",
    "    table.append([N_, data[0][0], data[1][0]])\n",
    "\n",
    "print(tabulate(table, headers=headers, tablefmt='github', floatfmt='.7f')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u estimator comparison\n",
      "\n",
      "|   basis size |   2 ncd corr |      3 pg |\n",
      "|--------------|--------------|-----------|\n",
      "|            4 |    1.1267376 | 1.1509328 |\n",
      "|            8 |    0.3245847 | 0.4675477 |\n",
      "|           12 |    0.1207877 | 0.1603159 |\n",
      "|           16 |    0.0983618 | 0.3130725 |\n",
      "|           20 |    0.0573171 | 0.2477959 |\n",
      "|           24 |    0.0120203 | 0.0837140 |\n",
      "|           28 |    0.0071521 | 0.0133642 |\n",
      "|           32 |    0.0061419 | 0.0160391 |\n",
      "|           36 |    0.0040785 | 0.0080779 |\n",
      "|           40 |    0.0023548 | 0.0161891 |\n",
      "|           44 |    0.0014752 | 0.0156381 |\n",
      "|           48 |    0.0009369 | 0.0028227 |\n",
      "|           52 |    0.0007637 | 0.0012630 |\n",
      "|           56 |    0.0007043 | 0.0009514 |\n",
      "|           60 |    0.0004982 | 0.0011383 |\n"
     ]
    }
   ],
   "source": [
    "# tabulate for the output functional\n",
    "print('u estimator comparison')\n",
    "print()\n",
    "headers = ['basis size', '2 ncd corr', '3 pg']\n",
    "table = []\n",
    "for i, N_ in enumerate(N):\n",
    "    data = u_data_for_N[i]\n",
    "    table.append([N_, data[0][1], data[1][1]])\n",
    "\n",
    "print(tabulate(table, headers=headers, tablefmt='github', floatfmt='.7f')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u eff comparison\n",
      "\n",
      "|   basis size |   2 ncd corr |      3 pg |\n",
      "|--------------|--------------|-----------|\n",
      "|            4 |    2.3370941 | 2.1009168 |\n",
      "|            8 |    2.7008045 | 2.1902928 |\n",
      "|           12 |    2.8514701 | 2.5112024 |\n",
      "|           16 |    2.6425123 | 2.4048731 |\n",
      "|           20 |    2.4331320 | 2.1785246 |\n",
      "|           24 |    2.5701722 | 2.2981771 |\n",
      "|           28 |    2.4724653 | 2.6184555 |\n",
      "|           32 |    2.4967537 | 2.5018695 |\n",
      "|           36 |    2.3312874 | 2.4064716 |\n",
      "|           40 |    2.3376798 | 2.4770070 |\n",
      "|           44 |    2.3116398 | 2.4189214 |\n",
      "|           48 |    2.3190044 | 2.4230626 |\n",
      "|           52 |    2.3070644 | 2.3285447 |\n",
      "|           56 |    2.2856160 | 2.3518146 |\n",
      "|           60 |    2.2815045 | 2.3705175 |\n"
     ]
    }
   ],
   "source": [
    "# tabulate for the output functional\n",
    "print('u eff comparison')\n",
    "print()\n",
    "headers = ['basis size', '2 ncd corr', '3 pg']\n",
    "table = []\n",
    "for i, N_ in enumerate(N):\n",
    "    data = u_data_for_N[i]\n",
    "    table.append([N_, data[0][4], data[1][4]])\n",
    "\n",
    "print(tabulate(table, headers=headers, tablefmt='github', floatfmt='.7f')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p error comparison\n",
      "\n",
      "|   basis size |   2 ncd corr |       3 pg |\n",
      "|--------------|--------------|------------|\n",
      "|            4 |   40.7460763 | 40.8146894 |\n",
      "|            8 |   38.8899377 | 39.3312537 |\n",
      "|           12 |   33.2418317 | 35.1527006 |\n",
      "|           16 |   23.2686215 | 35.3298773 |\n",
      "|           20 |    9.4626144 | 10.6842491 |\n",
      "|           24 |    4.1539872 | 10.9024490 |\n",
      "|           28 |    3.4412535 |  8.1679185 |\n",
      "|           32 |    2.8128896 | 12.9165319 |\n",
      "|           36 |    2.3952862 | 11.0609593 |\n",
      "|           40 |    1.2969305 |  8.8701537 |\n",
      "|           44 |    1.1588881 | 43.5757322 |\n",
      "|           48 |    0.9383411 |  5.3983823 |\n",
      "|           52 |    0.7765199 |  7.8105103 |\n",
      "|           56 |    0.6220427 |  5.2246835 |\n",
      "|           60 |    0.4001464 | 10.7762531 |\n"
     ]
    }
   ],
   "source": [
    "# tabulate for the output functional\n",
    "print('p error comparison')\n",
    "print()\n",
    "headers = ['basis size', '2 ncd corr', '3 pg']\n",
    "table = []\n",
    "for i, N_ in enumerate(N):\n",
    "    data = p_data_for_N[i]\n",
    "    table.append([N_, data[0][0], data[1][0]])\n",
    "\n",
    "print(tabulate(table, headers=headers, tablefmt='github', floatfmt='.7f')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p estimator comparison\n",
      "\n",
      "|   basis size |   2 ncd corr |         3 pg |\n",
      "|--------------|--------------|--------------|\n",
      "|            4 | 3314.4915026 | 3384.8566080 |\n",
      "|            8 | 1044.2122510 | 1490.4772010 |\n",
      "|           12 |  369.4921049 |  481.0013244 |\n",
      "|           16 |  302.9134902 |  949.3420514 |\n",
      "|           20 |  170.0176986 |  729.7500855 |\n",
      "|           24 |   45.8931937 |  251.4578324 |\n",
      "|           28 |   29.1145765 |   46.8772780 |\n",
      "|           32 |   25.0995237 |   76.5564492 |\n",
      "|           36 |   13.4125369 |   36.9286502 |\n",
      "|           40 |    9.0344776 |   51.5039700 |\n",
      "|           44 |    5.2009862 |  105.0721066 |\n",
      "|           48 |    4.0151371 |   13.1081584 |\n",
      "|           52 |    3.6330931 |   20.6958803 |\n",
      "|           56 |    3.3285899 |   10.4409919 |\n",
      "|           60 |    2.4240827 |   16.9395369 |\n"
     ]
    }
   ],
   "source": [
    "# tabulate for the output functional\n",
    "print('p estimator comparison')\n",
    "print()\n",
    "headers = ['basis size', '2 ncd corr', '3 pg']\n",
    "table = []\n",
    "for i, N_ in enumerate(N):\n",
    "    data = p_data_for_N[i]\n",
    "    table.append([N_, data[0][1], data[1][1]])\n",
    "\n",
    "print(tabulate(table, headers=headers, tablefmt='github', floatfmt='.7f')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p eff comparison\n",
      "\n",
      "|   basis size |   2 ncd corr |        3 pg |\n",
      "|--------------|--------------|-------------|\n",
      "|            4 |  218.0635773 | 317.1192860 |\n",
      "|            8 |  240.9262370 | 264.8889118 |\n",
      "|           12 |  132.5182053 | 165.5789741 |\n",
      "|           16 |  166.0367722 | 296.1618433 |\n",
      "|           20 |  161.4564837 | 229.7975367 |\n",
      "|           24 |  101.4277215 | 156.2206450 |\n",
      "|           28 |   83.5570571 |  86.5507879 |\n",
      "|           32 |   86.3793393 |  42.7870552 |\n",
      "|           36 |  141.1268178 |  61.5356621 |\n",
      "|           40 |  129.3485014 |  84.8022788 |\n",
      "|           44 |   84.9175004 | 185.5953308 |\n",
      "|           48 |   83.5895829 |  59.5990114 |\n",
      "|           52 |   84.7123282 |  32.4075792 |\n",
      "|           56 |   84.2958068 |  43.2952008 |\n",
      "|           60 |   73.8084284 |  15.7799905 |\n"
     ]
    }
   ],
   "source": [
    "# tabulate for the output functional\n",
    "print('p eff comparison')\n",
    "print()\n",
    "headers = ['basis size', '2 ncd corr', '3 pg']\n",
    "table = []\n",
    "for i, N_ in enumerate(N):\n",
    "    data = p_data_for_N[i]\n",
    "    table.append([N_, data[0][4], data[1][4]])\n",
    "\n",
    "print(tabulate(table, headers=headers, tablefmt='github', floatfmt='.7f')) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
